{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## MachineLearning 第一课实训参考答案\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简答题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.常见的机器学习任务有哪几大类别，具体说说每个类别又有哪些应用？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 回归方法任务\n",
    "回归方法是一种对数值型连续随机变量进行预测和建模的监督学习算法，也就是根据之前的数据建模，然后根据新的输入预测出一个准确的输出值。使用案例一般包括房价预测、股票走势或测试成绩等连续变化的案例。回归任务的特点是标注的数据集具有数值型的目标变量。也就是说，每一个观察样本都有一个数值型的标注真值以监督算法。\n",
    "\n",
    "##### 分类方法任务\n",
    "分类方法是一种对离散型随机变量建模或预测的监督学习算法，也就是将事物打上一个标签。使用案例包括邮件过滤、金融欺诈和预测雇员异动等输出为类别的任务。许多回归算法都有与其相对应的分类算法，分类算法通常适用于预测一个类别（或类别的概率）而不是连续的数值。\n",
    "\n",
    "##### 聚类方法任务\n",
    "聚类是一种无监督学习任务，该算法基于数据的内部结构寻找观察样本的自然族群（即集群）。使用案例包括细分客户、新闻聚类、文章推荐等。\n",
    "因为聚类是一种无监督学习（即数据没有标注），并且通常使用数据可视化评价结果。如果存在「正确的回答」（即在训练集中存在预标注的集群），那么分类算法可能更加合适。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.机器学习的学习策略大致可分为有监督学习与无监督学习，请谈谈您对这两类策略的认识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 监督学习\n",
    "从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括回归分析和统计分类。\n",
    "\n",
    "#### 无监督学习\n",
    "与监督学习相比，无监督学习的训练集没有人为标注的结果。常见的无监督学习算法有生成對抗網絡（GAN）、聚类。监督学习和非监督学习的差别就是训练集目标是否人标注。他们都有训练集 且都有输入和输出\n",
    "\n",
    "#### 增强学习/强化学习\n",
    "通过观察来学习做成如何的动作。每个动作都会对环境有所影响，学习对象根据观察到的周围环境的反馈来做出判断。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.列举你所知道的机器学习任务中的一些术语并给出解释。（例如，特征，标签，训练等）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 标签\n",
    "标签是我们要预测的事物，即简单线性回归中的 y 变量。对于一个预测香港赛马比赛的机器学习模型而言，标签可以是某一次比赛的名次、获得奖金池的大小等。\n",
    "\n",
    "##### 特征\n",
    "特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征。对于预测香港赛马比赛的机器学习模型而言，特征包括了马的年龄、历史上曾经获得的名次、骑师历史上获得过的名次等几百个甚至几千个特征。\n",
    "\n",
    "##### 样本\n",
    "样本是指数据的特定实例。样本可以分为两类：一、有标签样本，二、无标签样本。有标签样本同时包含特征和标签。把香港跑马比赛历史数据拿来，给每一次比赛加上标签，得到的就是一个有标签样本，否则就是一个无标签样本。\n",
    "\n",
    "##### 模型\n",
    "模型定义了特征与标签之间的关系。例如一个预测香港赛马的模型可能会将某些马和骑师的特征与“赢得比赛前三名”紧密联系起来。\n",
    "\n",
    "##### 训练\n",
    "训练表示创建或学习模型。通过向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。把香港跑马比赛的历史数据切出一部分，作为训练数据集输入到模型中，让模型学习马与骑师的特征与跑马比赛的名次之间的关系，这个过程就是训练。\n",
    "\n",
    "##### 推断/预测\n",
    "推断表示将训练后的模型应用于无标签样本。也就是说，您使用训练后的模型来做出有用的预测 (y')。例如香港跑马比赛的模型，在训练好之后，把新的赛程信息传入到模型中，由。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.什么是损失函数？请写出回归任务中的均方误差的数学公式，并解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子\n",
    "\n",
    "回归任务中的均方误差的数学公式(MSE)\n",
    "\n",
    "$$MSE = \\frac{1}{N}\\sum_{i=1}^N ( x_i - \\widehat{x}_i )^{2}$$\n",
    "\n",
    "其中$N$是数据样本数，$x_i$是第$i$个数据样板的真实值，$\\widehat{x}_i$是第$i$个数据点的观测值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.模型的泛化能力是指？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "泛化能力是模型中对新数据的预测能力。在实际中如果对训练数据能很好的拟合，而对验证集的效果较差，泛化能力较弱，可能出现过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.请给出查准率与查全率的公式和解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例(true positive)、假正例(false positive)、真反例(true negative)、假反例(false negative)四种情形，令TP、FP、TN、FN分别表示其对应的样例数，则显然有TP+FP+TN+FN=样例总数。分类结果的“混淆矩阵”(confusion matrix)如表1所示。\n",
    "<table cellspacing=\"0\" cellpadding=\"0\" style=\"width:670px;color:rgb(62,62,62);font-family:'Helvetica Neue', Helvetica, 'Hiragino Sans GB', 'Microsoft YaHei', Arial, sans-serif;font-size:16px;background-color:rgb(255,255,255);\"><tbody><tr><td rowspan=\"2\" valign=\"top\"><p style=\"clear:both;min-height:1em;text-align:center;\">真实情况</p></td><td colspan=\"2\" valign=\"top\" style=\"border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">预测结果</p></td></tr><tr><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">正例</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">反例</p></td></tr><tr><td valign=\"top\" style=\"border-top:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">正例</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">TP(真正例)</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">FN(假反例)</p></td></tr><tr><td valign=\"top\" style=\"border-top:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">反例</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">FP(假正例)</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">TN(真反例)</p></td></tr></tbody></table>\n",
    "查准率(Precision)，又叫准确率，缩写表示用P。查准率是针对我们预测结果而言的，它表示的是预测为正的样例中有多少是真正的正样例。定义公式如下\n",
    "\n",
    "$ P=\\frac{TP}{TP+FP} $\n",
    "\n",
    "查全率(Recall)，又叫召回率，缩写表示用R。查全率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确。定义公式如下\n",
    "\n",
    "$ P=\\frac{TP}{TP+FN} $\n",
    "\n",
    "查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。\n",
    "\n",
    "我们可以这样理解，在一个分类器中，你想要更高的查准率，那么你的阈值要设置的更高，只有这样才能有较高的把握确定我们预测是正例是真正例。一旦我们把阈值设置高了，那我们预测出正例的样本数就少了，那真正例数就更少了，查不全所有的正样例。\n",
    "\n",
    "举个例子来理解一下吧！例如，若希望将好瓜尽可能多地挑选出来，则可通过增加选瓜的数量来实现，如果将所有的西瓜都选上，那么所有的好瓜也必然都选上了，但这样查准率就会较低；若希望选出的瓜中好瓜比例尽可能高，则可只挑选最有把握的瓜，但这样就难免会漏掉不少好瓜，使得查全率较低。通常只有在一些简单任务中，才可能使查全率和查准率都很高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.为什么要为模型添加正则化项？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正则化是为了解决过拟合问题\n",
    "\n",
    "\n",
    "机器学习中几乎都可以看到损失函数后面会添加一个额外项，常用的额外项一般有两种，一般英文称作ℓ1-norm和ℓ2-norm，中文称作L1正则化和L2正则化，或者L1范数和L2范数。\n",
    "\n",
    "L1正则化和L2正则化可以看做是损失函数的惩罚项。所谓『惩罚』是指对损失函数中的某些参数做一些限制。对于线性回归模型，使用L1正则化的模型建叫做Lasso回归，使用L2正则化的模型叫做Ridge回归（岭回归）。下图是Python中Lasso回归的损失函数，式中加号后面一项α||w||1即为L1正则化项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.为什么线性回归、逻辑斯谛回归等被称为广义线性模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归模型、逻辑斯谛回归模型都可以看做输入特征$\\mathbf{x}$的线性组合$\\mathbf{w}\\cdot\\mathbf{x}+b$的形式。可以认为逻辑斯谛回归模型是以线性回归模型的输出作为其输入，再进行非线性的$sigmoid$函数映射进行二分类任务，或者进行非线性的$softmax$函数映射进行多分类。    \n",
    "\n",
    "线性回归模型：\n",
    "$$f\\left(\\mathbf{x}\\right)=\\mathbf{w}\\cdot\\mathbf{x}+b=\\sum_{i=1}^n w^{\\left(i\\right)}\\cdot x^{\\left(i\\right)}+b $$\n",
    "其中，$\\mathbf{x} \\in \\mathcal{X}\\subseteq \\mathbb{R}^{n}$是输入，$\\mathbf{w}=\\left(w^{\\left(1\\right)},w^{\\left(2\\right)},\\dots,w^{\\left(n\\right)}\\right)^\\top \\in \\mathbb{R}^{n}$和$b \\in \\mathbb{R}$是参数，$\\mathbf{w}$称为权值向量，$b$称为偏置，$\\mathbf{w} \\cdot \\mathbf{x}$为$\\mathbf{w}$和$\\mathbf{x}$的内积。  \n",
    "二项逻辑斯谛回归模型是如下的条件概率分布：\n",
    "$$\\begin{align*}   P \\left( y = 1 | \\mathbf{x} \\right) &=\\sigma\\left(\\mathbf{w}\\cdot\\mathbf{x}+b\\right)   \\\\ \n",
    "&=  \\dfrac{1}{1+\\exp{\\left(-\\left(\\mathbf{w} \\cdot \\mathbf{x} + b \\right)\\right)}}\n",
    "\\\\ &= \\dfrac{\\exp{\\left(\\mathbf{w} \\cdot \\mathbf{x} + b \\right)}}{1+\\exp{\\left( \\mathbf{w} \\cdot \\mathbf{x} + b \\right)}}\\\\\n",
    "P \\left( y = 0 | \\mathbf{x} \\right) &=  1- \\sigma\\left(\\mathbf{w}\\cdot\\mathbf{x}+b\\right)\n",
    "\\\\ &=\\dfrac{1}{1+\\exp{\\left( \\mathbf{w} \\cdot \\mathbf{x} + b \\right)}}\\end{align*}$$\n",
    "其中，$\\mathbf{x} \\in \\mathbb{R}^{n}$，$y \\in \\left\\{ 0, 1 \\right\\}$，$\\mathbf{w} \\in \\mathbb{R}^{n}$是权值向量，$b \\in \\mathbb{R}$是偏置，$\\mathbf{w} \\cdot \\mathbf{x}$为向量内积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.线性回归模型采用的什么类型的损失函数？为何选择这样的损失函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归模型的损失函数：平方损失损失函数\n",
    "$$L\\left(y,f\\left(\\mathbf{x}\\right)\\right)=\\left(y-f\\left(\\mathbf{x}\\right)\\right)^2$$\n",
    "因为线性回归任务是拟合连续值输出，平方损失不仅可以反映是否存在损失，而且可以度量损失的大小，所以线性回归模型采用平方损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.逻辑斯谛回归模型采用的什么类型的损失函数？为何选择这样的损失函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑斯谛回归模型（二分类）采用交叉熵损失函数：\n",
    "$$\\begin{align*} \\\\ l \\left( \\hat{\\mathbf{w}} \\right) = -\\sum_{i=1}^{N} \\left[ y_{i} \\log \\sigma \\left( \\hat{\\mathbf{w}}\\cdot\\hat{\\mathbf{x}}_{i} \\right) + \\left( 1 - y_{i} \\right) \\log \\left( 1 - \\sigma \\left( \\hat{\\mathbf{w}}\\cdot\\hat{\\mathbf{x}}_{i} \\right) \\right) \\right]\\end{align*} $$\n",
    "因为逻辑斯谛回归任务输出的是类别的概率分布，最小化交叉熵损失等价于最小化相对熵，度量概率分布间的相似程度，使得真实分布于预测分布近似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "144px",
    "left": "1674px",
    "right": "20px",
    "top": "153px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
