{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#3-决策树\" data-toc-modified-id=\"3-决策树-5\">3 决策树</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-特征选择\" data-toc-modified-id=\"3.1-特征选择-5.1\">3.1 特征选择</a></span></li><li><span><a href=\"#3.2-决策树生成\" data-toc-modified-id=\"3.2-决策树生成-5.2\">3.2 决策树生成</a></span></li><li><span><a href=\"#3.3-决策树剪枝\" data-toc-modified-id=\"3.3-决策树剪枝-5.3\">3.3 决策树剪枝</a></span></li><li><span><a href=\"#3.4-分类与回归树CART\" data-toc-modified-id=\"3.4-分类与回归树CART-5.4\">3.4 分类与回归树CART</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.4.1-回归树的生成\" data-toc-modified-id=\"3.4.1-回归树的生成-5.4.1\">3.4.1 回归树的生成</a></span></li><li><span><a href=\"#3.4.2-分类树的生成\" data-toc-modified-id=\"3.4.2-分类树的生成-5.4.2\">3.4.2 分类树的生成</a></span></li><li><span><a href=\"#3.4.3-CART树剪枝\" data-toc-modified-id=\"3.4.3-CART树剪枝-5.4.3\">3.4.3 CART树剪枝</a></span></li></ul></li><li><span><a href=\"#3.5-决策树的实现及应用\" data-toc-modified-id=\"3.5-决策树的实现及应用-5.5\">3.5 决策树的实现及应用</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.5.1-信息增益计算\" data-toc-modified-id=\"3.5.1-信息增益计算-5.5.1\">3.5.1 信息增益计算</a></span></li><li><span><a href=\"#3.5.2-决策树生成的ID3算法\" data-toc-modified-id=\"3.5.2-决策树生成的ID3算法-5.5.2\">3.5.2 决策树生成的ID3算法</a></span></li><li><span><a href=\"#3.5.3-决策树分类的sklearn调用\" data-toc-modified-id=\"3.5.3-决策树分类的sklearn调用-5.5.3\">3.5.3 决策树分类的sklearn调用</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树是基于树结构来对实例进行决策的一种基本的分类和回归的机器学习方法。决策树由结点和有向边组成，结点分为内部结点（表示一个特征的划分）和叶子结点（表示一个类别或输出）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树学习，训练数据集\n",
    "\\begin{align*} \\\\& D = \\left\\{ \\left( \\mathbf{x}_{1}, y_{1} \\right), \\left( \\mathbf{x}_{2}, y_{2} \\right), \\cdots, \\left(\\mathbf{x}_i,y_i\\right),\\cdots,\\left( \\mathbf{x}_{N}, y_{N} \\right) \\right\\} \\end{align*}   \n",
    "其中，$\\mathbf{x}_{i}$为第$i$个特征向量（实例），$\\mathbf{x}_{i}=\\left( x^{\\left(1\\right)}_i,x^{\\left(2\\right)}_i,\\ldots ,x^{\\left(j\\right)}_i,\\ldots ,x^{\\left(n\\right)}_i\\right) ^{T} \\in \\mathcal{X} \\subseteq \\mathbb{R}^{n}$；$y_{i}$为$\\mathbf{x}_{i}$的类别标记，$y_i\\in\\{1,2,\\cdots,K\\}$。学习的目标数是根据给定的训练数据集构建一个决策树模型，使得可对实例进行正确的分类或回归。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树学习包括3个步骤：特征选择、决策树生成、决策树修剪。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 特征选择在于选取对于训练数据具有分类能力的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "熵表示随机变量不确定性的度量。  (信息论也很重要，里面很重要的工具、结论、原理，为机器学习模型构建指明了方向，提供了很好的数学工具)\n",
    "\n",
    "设$X$是一个取有限个值的离散随机变量，其概率分布为\n",
    "\\begin{align*} P \\left( X = x_{i} \\right) = p_{i}, \\quad i =1, 2, \\cdots, n \\end{align*}  \n",
    "则随机变量$X$的熵\n",
    "\\begin{align*} H \\left( X \\right) = H \\left( p \\right) = - \\sum_{i=1}^{n} p_{i} \\log p_{i} \\end{align*}   \n",
    "其中，若$p_{i}=0$，则定义$0 \\log 0 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若\n",
    "\\begin{align*} p_{i} = \\dfrac{1}{n} \\end{align*}   \n",
    "则\n",
    "\\begin{align*} \\\\ & H \\left( p \\right) = - \\sum_{i=1}^{n} p_{i} \\log p_{i} \n",
    "\\\\ & = - \\sum_{i=1}^{n} \\dfrac{1}{n} \\log \\dfrac{1}{n}\n",
    "\\\\ & = \\log n\\end{align*} \n",
    "由定义，得\n",
    "\\begin{align*} \\\\ & 0 \\leq H \\left( p \\right) \\leq \\log n\\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设有随机变量$\\left( X , Y \\right)$，其联合分布\n",
    "\\begin{align*} \\\\ & P \\left( X = x_{i}, Y = y_{j} \\right) = p_{ij}, \\quad i=1,2, \\cdots, n; \\quad j=1,2, \\cdots, m\\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机变量$X$给定的条件下随机变量$Y$的条件熵\n",
    "\\begin{align*} \\\\ & H \\left( Y | X \\right) = \\sum_{i=1}^{n} p_{i} H \\left( Y | X = x_{i} \\right) \\end{align*}  \n",
    "即，$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望。其中，$p_{i}=P \\left( X = x_{i} \\right), i= 1,2,\\cdots,n$。  \n",
    "条件熵$H \\left( Y | X \\right)$表示在已知随机变量$X$的条件下随机变量$Y$的不确定性。\n",
    "\n",
    "（$ H ( Y | X)  < & H( Y ) $）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征$A$对训练集$D$的信息增益\n",
    "\\begin{align*} \\\\ & g \\left( D, A \\right) = H \\left( D \\right) - H \\left( D | A \\right) \\end{align*}   \n",
    "即，集合$D$的经验熵$H \\left( D \\right)$与特征$A$给定条件下$D$的经验条件熵$H \\left( D | A \\right)$之差。  \n",
    "其中，当熵和条件熵由数据估计（极大似然估计）得到时，对应的熵和条件熵分别称为经验熵和经验条件熵。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设训练数据集为$D$，$\\left| D \\right|$表示其样本容量，即样本个数。  \n",
    "设有$K$个类$C_{k}, k=1,2,\\cdots,K$，$\\left| C_{k} \\right|$为属于类$C_{k}$的样本的个数，$\\sum_{k=1}^{K} \\left| C_{k} \\right| = \\left| D \\right|$。  \n",
    "设特征$A$有$n$个不同的特征取值$\\left\\{ a_{1},a_{2},\\cdots,a_{n}\\right\\}$，根据特征$A$的取值将$D$划分为$n$个子集$D_{1},D_{2},\\cdots,D_{n}$，$\\left| D_{i} \\right|$为$D_{i}$的样本数，$\\sum_{i=1}^{n}\\left| D_{i} \\right| = \\left| D \\right|$。  \n",
    "记子集$D_{i}$中属于类$C_{k}$的样本的集合为$D_{ik}$，即$D_{ik} = D_{i} \\cap C_{k}$，$\\left| D_{ik} \\right|$为$D_{ik}$的样本个数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益算法：  \n",
    "输入：训练数据集$D$和特征$A$  \n",
    "输出：特征$A$对训练数据集$D$的信息增益$g \\left( D, A \\right) $\n",
    "1. 计算数据集$D$的经验熵$H\\left(D\\right)$  \n",
    "\\begin{align*} \\\\ &  H \\left( D \\right) = -\\sum_{k=1}^{K} \\dfrac{\\left|C_{k}\\right|}{\\left| D \\right|}\\log_{2}\\dfrac{\\left|C_{k}\\right|}{\\left| D \\right|} \\end{align*}\n",
    "2. 计算特征$A$对数据集$D$的经验条件熵$H \\left( D | A \\right)$\n",
    "\\begin{align*} \\\\ & H \\left( D | A \\right) = \\sum_{i=1}^{n} \\dfrac{\\left| D_{i} \\right|}{\\left| D \\right|} H \\left( D_{i} \\right)\n",
    "\\\\ & = -\\sum_{i=1}^{n} \\dfrac{\\left| D_{i} \\right|}{\\left| D \\right|} \\sum_{k=1}^{K} \\dfrac{\\left| D_{ik} \\right|}{\\left| D_{i} \\right|} \\log_{2} \\dfrac{\\left| D_{ik} \\right|}{\\left| D_{i} \\right|}\\end{align*}\n",
    "3. 计算信息增益\n",
    "\\begin{align*} \\\\ & g \\left( D, A \\right) = H \\left( D \\right) - H \\left( D | A \\right) \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征$A$对训练集$D$的信息增益比\n",
    "\\begin{align*} \\\\ & g_{R} \\left( D, A \\right) = \\dfrac{g \\left( D, A \\right)}{H_{A} \\left(D\\right)}\\end{align*}   \n",
    "即，信息增益$g\\left( D, A \\right)$与训练数据集$D$关于特征$A$的经验熵$H_{A}\\left(D\\right)$之比。  \n",
    "其中，\n",
    "\\begin{align*} \\\\ & H_{A} \\left( D \\right) = -\\sum_{i=1}^{n} \\dfrac{\\left|D_{i}\\right|}{\\left|D\\right|}\\log_{2}\\dfrac{\\left|D_{i}\\right|}{\\left|D\\right|}\\end{align*}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以信息增益为特征选择标准偏向取值较多的特征。当特征的取值较多时，根据此特征划分更容易得到纯度更高的子集，因此划分之后的熵更低。由于划分前的熵是一定的，因此信息增益更大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以信息增益比为特征选择标准偏向取值较少的特征。当特征取值较少时$H_A\\left(D\\right)$的值较小，因此其倒数较大，因而信息增益比较大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 决策树生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ID3算法：  \n",
    "输入：训练数据集$D$，特征集合$A$，阈值$\\varepsilon$  \n",
    "输出：决策树$T$\n",
    "1. 若$D$中所有实例属于同一类$C_{k}$，则$T$为单结点树，并将类$C_{k}$作为该结点的类标记，返回$T$； \n",
    "2. 若$A = \\emptyset$（空集），则$T$为单结点树，并将$D$中实例数最大的类$C_{k}$作为该结点的类标记，返回$T$；\n",
    "3. 否则，计算$A$中各特征对$D$的信息增益，选择信息增益最大的特征$A_{g}$\n",
    "\\begin{align*} \\\\ & A_{g} = \\mathop{\\arg \\max}_{A_i\\in A} g \\left( D, A_i \\right) \\end{align*}  \n",
    "4. 如果$A_{g}$的信息增益小于阈值$\\varepsilon$，则置$T$为单结点树，并将$D$中实例数量最大的类$C_{k}$作为该结点的类标记，返回$T$;\n",
    "5. 否则，对$A_{g}$的每一个可能值$a_{i}$，依$A_{g}=a_{i}$将$D$分割为若干非空子集$D_{i}$，将$D_{i}$中实例数对大的类作为标记，构建子结点，由结点及其子结点构成树$T$，返回$T$；\n",
    "6. 对第$i$个子结点，以$D_{i}$为训练集，以$A-\\left\\{A_{g}\\right\\}$为特征集，递归地调用步1.～步5.，得到子树$T_{i}$，返回$T_{i}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "C4.5算法：  \n",
    "输入：训练数据集$D$，特征集合$A$，阈值$\\varepsilon$  \n",
    "输出：决策树$T$\n",
    "1. 若$D$中所有实例属于同一类$C_{k}$，则$T$为单结点树，并将类$C_{k}$作为该结点的类标记，返回$T$； \n",
    "2. 若$A = \\emptyset$，则$T$为单结点树，并将$D$中实例数最大的类$C_{k}$作为该结点的类标记，返回$T$；\n",
    "3. 否则，计算$A$中各特征对$D$的信息增益，选择信息增益比最大的特征$A_{g}$\n",
    "\\begin{align*} \\\\ & A_{g} = \\mathop{\\arg \\max}_{A_i\\in A} g_{R} \\left( D, A_i \\right) \\end{align*}  \n",
    "4. 如果$A_{g}$的信息增益小于阈值$\\varepsilon$，则置$T$为单结点树，并将$D$中实例数量最大的类$C_{k}$作为该结点的类标记，返回$T$;\n",
    "5. 否则，对$A_{g}$的每一个可能值$a_{i}$，依$A_{g}=a_{i}$将$D$分割为若干非空子集$D_{i}$，将$D_{i}$中实例数对大的类作为标记，构建子结点，由结点及其子结点构成树$T$，返回$T$；\n",
    "6. 对第$i$个子结点，以$D_{i}$为训练集，以$A-\\left\\{A_{g}\\right\\}$为特征集，递归地调用步1.～步5.，得到子树$T_{i}$，返回$T_{i}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 决策树剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的剪枝通过极小化决策树整体的损失函数或代价函数来实现。  \n",
    "设树$T$的叶结点个数为$\\left| T \\right|$，$t$是树$T$的叶结点，该叶结点有$N_{t}$个样本点，其中$k$类的样本点有$N_{tk}$个，$k=1,2,\\cdots,K$，$H_{t}\\left(T\\right)$为叶结点$t$上的经验熵，  \n",
    "则决策树的损失函数\n",
    "\\begin{align*} \\\\ & C_{\\alpha} \\left( T \\right) = \\sum_{t=1}^{\\left| T \\right|} N_{t} H_{t} \\left( T \\right) + \\alpha \\left| T \\right| \\end{align*}   \n",
    "其中，$\\alpha \\geq 0$为参数，经验熵\n",
    "\\begin{align*} \\\\ & H_{t} \\left( T \\right) = - \\sum_{k} \\dfrac{N_{tk}}{N_{t}} \\log \\dfrac{N_{tk}}{N_{t}} \\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数中，记\n",
    "\\begin{align*} \\\\ & C \\left( T \\right) = \\sum_{t=1}^{\\left| T \\right|} N_{t} H_{t} \\left( T \\right) = - \\sum_{t=1}^{\\left| T \\right|} \\sum_{k=1}^{K} N_{tk} \\log \\dfrac{N_{tk}}{N_{t}}   \\end{align*}   \n",
    "则\n",
    "\\begin{align*} \\\\ & C_{\\alpha} \\left( T \\right) = C \\left( T \\right) + \\alpha \\left| T \\right|   \\end{align*}  \n",
    "其中，$C \\left( T \\right)$表示模型对训练数据的预测误差，即模型与训练数据的拟合程度，$\\left| T \\right|$表示模型复杂度，参数$\\alpha \\geq 0$控制两者之间的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "树的剪枝算法：  \n",
    "输入：决策树$T$，参数$\\alpha$   \n",
    "输出：修剪后的子树$T_{\\alpha}$\n",
    "1. 计算每个结点的经验熵 \n",
    "2. 递归地从树的叶结点向上回缩  \n",
    "设一组叶结点回缩到其父结点之前与之后的整体树分别为$T_{B}$与$T_{A}$，其对应的损失函数值分别是$C_{\\alpha} \\left( T_{B} \\right)$与$C_{\\alpha} \\left( T_{A} \\right)$，如果\n",
    "\\begin{align*} \\\\ & C_{\\alpha} \\left( T_{A} \\right) \\leq C_{\\alpha} \\left( T_{B} \\right)  \\end{align*}\n",
    "则进行剪枝，即将父结点变为新的叶结点。\n",
    "3. 返回2.，直到不能继续为止，得到损失函数最小的子树$T_{\\alpha}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 分类与回归树CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 回归树的生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个回归树对应着输入空间的一个划分以及在划分单元上的输出值。假设已将输入空间划分为$M$个单元$R_1,R_2,\\cdots,R_M$，并且在每个单元$R_m$上有一个固定的输出值$c_m$，于是回归树模型可表示为\n",
    "$$f\\left(\\mathbf{x}\\right)=\\sum_{m=1}^M c_m I\\left(\\mathbf{x}\\in R_m\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树本质上就是对输入空间的离散化，并对每个子空间进行类别确认。$f(\\mathbf{x})$ 是一棵树， $I$ 是个指示（条件）函数，当$(\\mathbf{x}\\in R_m)$条件成立时返回1，否则返回0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "假设$X$与$Y$分别为输入和输出变量，并且$Y$是连续变量，给定训练数据集\n",
    "\\begin{align*} \\\\ & D = \\left\\{  \\left(\\mathbf{x}_{1},y_{1}\\right), \\left(\\mathbf{x}_{2},y_{2}\\right),\\cdots,\\left(\\mathbf{x}_{N},y_{N}\\right) \\right\\}   \\end{align*}    \n",
    "可选择第$j$个变量$x^{\\left(j\\right)}$及其取值$s$作为切分变量和切分点，并定义两个区域\n",
    "\\begin{align*} \\\\ & R_{1} \\left( j,s \\right) = \\left\\{ x | x^{\\left(j\\right)} \\leq s \\right\\}, \\quad R_{2} \\left( j,s \\right) = \\left\\{ x | x^{\\left(j\\right)} > s \\right\\}   \\end{align*}\n",
    "最优切分变量$x_{j}$及最优切分点$s$\n",
    "\\begin{align*} \\\\ & j,s = \\mathop{\\arg \\min}_{j,s} \\left[ \\min_{c_{1}} \\sum_{x_{i} \\in R_{1} \\left(j,s\\right)} \\left( y_{i} - c_{1} \\right)^{2} + \\min_{c_{2}} \\sum_{x_{i} \\in R_{2} \\left(j,s\\right)} \\left( y_{i} - c_{2} \\right)^{2}\\right]   \\end{align*}  \n",
    "其中，$c_{m}$是区域$R_{m}$上的回归决策树输出，是区域$R_{m}$上所有输入实例$x_{i}$对应的输出$y_{i}$的均值\n",
    "\\begin{align*} \\\\ & c_{m} = ave \\left( y_{i} | x_{i} \\in R_{m} \\right), \\quad m=1,2   \\end{align*}  \n",
    "对每个区域$R_{1}$和$R_{2}$重复上述过程，将输入空间划分为$M$个区域$R_{1},R_{2},\\cdots,R_{M}$，在每个区域上的输出为$c_{m},m=1,2,\\cdots,M$，最小二乘回归树\n",
    "\\begin{align*} \\\\ & f \\left( x \\right) = \\sum_{m=1}^{M} c_{m} I \\left( x \\in R_{m} \\right)   \\end{align*}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最小二乘回归树生成算法：  \n",
    "输入：训练数据集$D$   \n",
    "输出：回归树$f \\left( x \\right)$\n",
    "1. 选择最优切分变量$x^{\\left(j\\right)}$与切分点$s$\n",
    "\\begin{align*} \\\\ & j,s = \\arg \\min_{j,s} \\left[ \\min_{c_{1}} \\sum_{x_{i} \\in R_{1} \\left(j,s\\right)} \\left( y_{i} - c_{1} \\right)^{2} + \\min_{c_{2}} \\sum_{x_{i} \\in R_{2} \\left(j,s\\right)} \\left( y_{i} - c_{2} \\right)^{2}\\right]   \\end{align*}  \n",
    "2. 用最优切分变量$x^{\\left(j\\right)}$与切分点$s$划分区域并决定相应的输出值 \n",
    "\\begin{align*} \\\\ & R_{1} \\left( j,s \\right) = \\left\\{ x | x^{\\left(j\\right)} \\leq s \\right\\}, \\quad R_{2} \\left( j,s \\right) = \\left\\{ x | x^{\\left(j\\right)} > s \\right\\}   \n",
    "\\\\ & c_{m} = \\dfrac{1}{N} \\sum_{x_{i} \\in R_{m} \\left( j,s \\right)} y_{i}, \\quad m=1,2\\end{align*}\n",
    "3. 继续对两个子区域调用步骤1.和2.，直到满足停止条件\n",
    "4. 将输入空间划分为$M$个区域$R_{1},R_{2},\\cdots,R_{M}$，生成决策树\n",
    "\\begin{align*} \\\\ & f \\left( x \\right) = \\sum_{m=1}^{M} c_{m} I \\left( x \\in R_{m} \\right)   \\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 分类树的生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类问题中，假设有$K$个类，样本点属于第$k$类的概率为$p_{k}$，则概率分布的基尼指数\n",
    "\\begin{align*} \\\\ & Gini \\left( p \\right) = \\sum_{k=1}^{K} p_{k} \\left( 1 - p_{k} \\right) = 1 - \\sum_{k=1}^{K}p_k^2  \\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二分类问题，若样本点属于第1类的概率为$p$，则概率分布的基尼指数\n",
    "\\begin{align*} \\\\ & Gini \\left( p \\right) = \\sum_{k=1}^{2} p_{k} \\left( 1 - p_{k} \\right) = 2p\\left(1-p\\right) \\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于给定样本集和$D$，其基尼指数\n",
    "\\begin{align*} \\\\ & Gini \\left( D \\right) = 1 - \\sum_{k=1}^{K} \\left( \\dfrac{\\left| C_{k} \\right|}{\\left| D \\right|} \\right)^{2}\\end{align*}   \n",
    "其中，$C_{k}$是$D$中属于第$k$类的样本自己，$K$是类别个数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果样本集合$D$根据特征$A$是否取某一可能值$a$被分割成$D_{1}$和$D_{2}$两个部分，即\n",
    "\\begin{align*} \\\\ & D_{1} = \\left\\{ \\left(x,y\\right) | A\\left(x\\right)=a \\right\\}, \\quad D_{2} = D - D_{1} \\end{align*} \n",
    "则在特征$A$的条件下，集合$D$的基尼指数\n",
    "\\begin{align*} \\\\ & Gini \\left( D, A \\right) = \\dfrac{\\left| D_{1} \\right|}{\\left| D \\right|} Gini \\left( D_{1} \\right) + \\dfrac{\\left| D_{2} \\right|}{\\left| D \\right|} Gini \\left( D_{2} \\right)\\end{align*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基尼指数$Gini \\left( D \\right)$表示集合$D$的不确定性，基尼指数$Gini \\left( D,A \\right)$表示经$A=a$分割后集合$D$的不确定性。基尼指数值越大，样本集合的不确定性也越大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART生成算法：  \n",
    "输入：训练数据集$D$，特征$A$，阈值$\\varepsilon$  \n",
    "输出：CART决策树$T$\n",
    "1. 设结点的训练数据集为$D$，对每一个特征$A$，对其可能取的每个值$a$，根据样本点对$A=a$的测试为“是”或“否”将$D$分割成$D_{1}$和$D_{2}$两部分，并计算$Gini\\left(D,A\\right)$\n",
    "2. 在所有可能的特征$A$以及其所有可能的切分点$a$中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。依此从现结点生成两个子结点，将训练数据集依特征分配到两个子结点中去。\n",
    "3. 对两个子结点递归地调用1.和2.，直至满足停止条件\n",
    "4. 生成CART决策树$T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 CART树剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "对整体树$T_{0}$任意内部结点$t$，以$t$为单结点树的损失函数\n",
    "\\begin{align*} \\\\ & C_{\\alpha} \\left( t \\right) = C \\left( t \\right) + \\alpha \\end{align*} \n",
    "以$t$为根结点的子树$T_{t}$的损失函数\n",
    "\\begin{align*} \\\\ & C_{\\alpha} \\left( T_{t} \\right) = C \\left( T_{t} \\right) + \\alpha \\left| T_{t} \\right| \\end{align*} \n",
    "当$\\alpha = 0$及$\\alpha$充分小时，有不等式\n",
    "\\begin{align*} \\\\ & C_{\\alpha} \\left( T_{t} \\right) <  C_{\\alpha} \\left( t \\right) \\end{align*} \n",
    "当$\\alpha$增大时，在某一$\\alpha$有\n",
    "\\begin{align*} \\\\ & \\quad\\quad C_{\\alpha} \\left( T_{t} \\right)  ＝  C_{\\alpha} \\left( t \\right) \n",
    "\\\\ & C \\left( T_{t} \\right) + \\alpha \\left| T_{t} \\right| ＝ C \\left( t \\right) + \\alpha\n",
    "\\\\ & \\quad\\quad \\alpha = \\dfrac{C\\left( t \\right) - C \\left(T_{t}\\right)} { \\left| T_{t} \\right| -1 }\\end{align*} \n",
    "即$T_{t}$与$t$有相同的损失函数值，而$t$的结点少，因此对$T_{t}$进行剪枝。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART剪枝算法：  \n",
    "输入：CART决策树$T_{0}$   \n",
    "输出：最优决策树$T_{\\alpha}$\n",
    "1. 设$k=0, T=T_{0}$\n",
    "2. 设$\\alpha=+\\infty$\n",
    "3. 自下而上地对各内部结点$t$计算$ C\\left(T_{t}\\right),\\left| T_{t} \\right|$，以及\n",
    "\\begin{align*} \\\\ & g\\left(t\\right) =  \\dfrac{C\\left( t \\right) - C \\left(T_{t}\\right)} { \\left| T_{t} \\right| -1 }\n",
    "\\\\ & \\alpha = \\min \\left( \\alpha, g\\left( t \\right) \\right) \\end{align*} \n",
    "其中，$T_{t}$表示以$t$为根结点的子树，$ C\\left(T_{t}\\right)$是对训练数据的预测误差，$\\left| T_{t} \\right|$是$T_{t}$的叶结点个数。\n",
    "4. 自下而上地访问内部结点$t$，如果有$g\\left(t\\right)=\\alpha$，则进行剪枝，并对叶结点$t$以多数表决法决定其类别，得到树$T$\n",
    "5. 设$k=k+1, \\alpha_{k}=\\alpha, T_{k}=T$\n",
    "6. 如果$T$不是由根结点单独构成的树，则回到步骤4.\n",
    "7. 采用交叉验证法在子树序列$T_{0},T_{1},\\cdots,T_{n}$中选取最优子树$T_{\\alpha}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 决策树的实现及应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 信息增益计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:24:06.954425Z",
     "start_time": "2019-11-26T09:24:05.892905Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T06:34:31.577340Z",
     "start_time": "2019-11-26T06:34:31.568398Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    datasets = [['青年', '否', '否', '一般', '否'],\n",
    "                ['青年', '否', '否', '好', '否'],\n",
    "                ['青年', '是', '否', '好', '是'],\n",
    "                ['青年', '是', '是', '一般', '是'],\n",
    "                ['青年', '否', '否', '一般', '否'],\n",
    "                ['中年', '否', '否', '一般', '否'],\n",
    "                ['中年', '否', '否', '好', '否'],\n",
    "                ['中年', '是', '是', '好', '是'],\n",
    "                ['中年', '否', '是', '非常好', '是'],\n",
    "                ['中年', '否', '是', '非常好', '是'],\n",
    "                ['老年', '否', '是', '非常好', '是'],\n",
    "                ['老年', '否', '是', '好', '是'],\n",
    "                ['老年', '是', '否', '好', '是'],\n",
    "                ['老年', '是', '否', '非常好', '是'],\n",
    "                ['老年', '否', '否', '一般', '否'],]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "    \n",
    "    return datasets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T06:34:34.382898Z",
     "start_time": "2019-11-26T06:34:34.370312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年龄</th>\n",
       "      <th>有工作</th>\n",
       "      <th>有自己的房子</th>\n",
       "      <th>信贷情况</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>一般</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    年龄 有工作 有自己的房子 信贷情况 类别\n",
       "0   青年   否      否   一般  否\n",
       "1   青年   否      否    好  否\n",
       "2   青年   是      否    好  是\n",
       "3   青年   是      是   一般  是\n",
       "4   青年   否      否   一般  否\n",
       "5   中年   否      否   一般  否\n",
       "6   中年   否      否    好  否\n",
       "7   中年   是      是    好  是\n",
       "8   中年   否      是  非常好  是\n",
       "9   中年   否      是  非常好  是\n",
       "10  老年   否      是  非常好  是\n",
       "11  老年   否      是    好  是\n",
       "12  老年   是      否    好  是\n",
       "13  老年   是      否  非常好  是\n",
       "14  老年   否      否   一般  否"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets, labels = create_data()\n",
    "train_data = pd.DataFrame(datasets, columns=labels)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T07:02:43.067810Z",
     "start_time": "2019-11-26T07:02:43.062193Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_ent(datasets):\n",
    "    data_length = len(datasets)\n",
    "    label_count = {}\n",
    "    for i in range(data_length):\n",
    "        label = datasets[i][-1]\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += 1\n",
    "    ent = -sum([(p / data_length) * math.log(p / data_length, 2) \n",
    "                for p in label_count.values()])\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T07:02:44.092195Z",
     "start_time": "2019-11-26T07:02:44.087387Z"
    }
   },
   "outputs": [],
   "source": [
    "def cond_ent(datasets, axis=0):\n",
    "    data_length = len(datasets)\n",
    "    feature_sets = {}\n",
    "    for i in range(data_length):\n",
    "        feature = datasets[i][axis]\n",
    "        if feature not in feature_sets:\n",
    "            feature_sets[feature] = []\n",
    "        feature_sets[feature].append(datasets[i])\n",
    "    cond_ent = sum([(len(p) / data_length) * calc_ent(p)\n",
    "                    for p in feature_sets.values()])\n",
    "    return cond_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T07:02:44.872679Z",
     "start_time": "2019-11-26T07:02:44.867911Z"
    }
   },
   "outputs": [],
   "source": [
    "def info_gain(ent, cond_ent):\n",
    "    return ent - cond_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T07:03:13.180170Z",
     "start_time": "2019-11-26T07:03:13.173705Z"
    }
   },
   "outputs": [],
   "source": [
    "def info_gain_train(datasets):\n",
    "    count = len(datasets[0]) - 1\n",
    "    ent = calc_ent(datasets)\n",
    "    best_feature = []\n",
    "    for c in range(count):\n",
    "        c_info_gain = info_gain(ent, cond_ent(datasets, axis=c))\n",
    "        best_feature.append((c, c_info_gain))\n",
    "        print('特征({}) - info_gain - {:.3f}'.format(labels[c], c_info_gain))\n",
    "        \n",
    "    best_ = max(best_feature, key=lambda x: x[-1])\n",
    "    return '特征({})的信息增益最大，选择为根节点特征'.format(labels[best_[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T07:03:13.951410Z",
     "start_time": "2019-11-26T07:03:13.944644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征(年龄) - info_gain - 0.083\n",
      "特征(有工作) - info_gain - 0.324\n",
      "特征(有自己的房子) - info_gain - 0.420\n",
      "特征(信贷情况) - info_gain - 0.363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'特征(有自己的房子)的信息增益最大，选择为根节点特征'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_gain_train(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 决策树生成的ID3算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:08:14.355527Z",
     "start_time": "2019-11-26T09:08:14.341088Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {'label:': self.label, 'feature:': self.feature, 'tree:': self.tree}\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "    \n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "    \n",
    "    def predict(self, features):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:08:29.200130Z",
     "start_time": "2019-11-26T09:08:29.183972Z"
    }
   },
   "outputs": [],
   "source": [
    "class DTree:\n",
    "    \n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    def calc_ent(datasets):\n",
    "        data_length = len(datasets)\n",
    "        label_count = {}\n",
    "        for i in range(data_length):\n",
    "            label = datasets[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        ent = -sum([(p / data_length) * math.log(p / data_length, 2) \n",
    "                for p in label_count.values()])\n",
    "        return ent\n",
    "\n",
    "    def cond_ent(self, datasets, axis=0):\n",
    "        data_length = len(datasets)\n",
    "        feature_sets = {}\n",
    "        for i in range(data_length):\n",
    "            feature = datasets[i][axis]\n",
    "            if feature not in feature_sets:\n",
    "                feature_sets[feature] = []\n",
    "            feature_sets[feature].append(datasets[i])\n",
    "        cond_ent = sum([(len(p) / data_length) * self.calc_ent(p)\n",
    "                    for p in feature_sets.values()])\n",
    "        return cond_ent\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_gain(ent, cond_ent):\n",
    "        return ent - cond_ent\n",
    "    \n",
    "    def info_gain_train(self, datasets):\n",
    "        count = len(datasets[0]) - 1\n",
    "        ent = self.calc_ent(datasets)\n",
    "        best_feature = []\n",
    "        for c in range(count):\n",
    "            c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "        \n",
    "        best_ = max(best_feature, key=lambda x: x[-1])\n",
    "        return best_\n",
    "    \n",
    "    def train(self, train_data):\n",
    "        _, y_train, features = train_data.iloc[:, :-1], train_data.iloc[:, -1], train_data.columns[:-1]\n",
    "        \n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root=True, label=y_train.iloc[0])\n",
    "        \n",
    "        if len(features) == 0:\n",
    "            return Node(root=True,\n",
    "                        label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "        max_feature, max_info_gain = self.info_gain_train(np.array(train_data))\n",
    "        max_feature_name = features[max_feature]\n",
    "        \n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(root=True,\n",
    "                        label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "        node_tree = Node(root=False, feature_name=max_feature_name, feature=max_feature)\n",
    "        \n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "        for f in feature_list:\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop([max_feature_name], axis=1)\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "        \n",
    "        #pprint.pprint(node_tree.tree)\n",
    "        return node_tree\n",
    "    \n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return self._tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:08:30.107091Z",
     "start_time": "2019-11-26T09:08:30.087477Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets, labels = create_data()\n",
    "data_df = pd.DataFrame(datasets, columns=labels)\n",
    "dt = DTree()\n",
    "tree = dt.fit(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:08:31.795994Z",
     "start_time": "2019-11-26T09:08:31.790878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label:': None, 'feature:': 2, 'tree:': {'否': {'label:': None, 'feature:': 1, 'tree:': {'否': {'label:': '否', 'feature:': None, 'tree:': {}}, '是': {'label:': '是', 'feature:': None, 'tree:': {}}}}, '是': {'label:': '是', 'feature:': None, 'tree:': {}}}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:09:49.251689Z",
     "start_time": "2019-11-26T09:09:49.245309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'否'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(['老年', '否', '否', '一般'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 决策树分类的sklearn调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:23:39.667105Z",
     "start_time": "2019-11-26T09:23:39.652580Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:28:02.395321Z",
     "start_time": "2019-11-26T09:28:02.390923Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    return data[:, :2], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:29:11.586007Z",
     "start_time": "2019-11-26T09:29:11.576131Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:29:36.143251Z",
     "start_time": "2019-11-26T09:29:36.126039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:29:53.105518Z",
     "start_time": "2019-11-26T09:29:53.097557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:30:47.592228Z",
     "start_time": "2019-11-26T09:30:47.585552Z"
    }
   },
   "outputs": [],
   "source": [
    "tree_pic = export_graphviz(clf, out_file='mytree.pdf')\n",
    "with open('mytree.pdf') as f:\n",
    "    dot_graph = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T09:31:06.701983Z",
     "start_time": "2019-11-26T09:30:58.615771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"445pt\" height=\"477pt\"\n",
       " viewBox=\"0.00 0.00 445.00 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-473 441,-473 441,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"271,-469 165,-469 165,-401 271,-401 271,-469\"/>\n",
       "<text text-anchor=\"middle\" x=\"218\" y=\"-453.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 5.45</text>\n",
       "<text text-anchor=\"middle\" x=\"218\" y=\"-438.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"218\" y=\"-423.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 70</text>\n",
       "<text text-anchor=\"middle\" x=\"218\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [34, 36]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"209.5,-365 110.5,-365 110.5,-297 209.5,-297 209.5,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 2.8</text>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.278</text>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 36</text>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [30, 6]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M199.0086,-400.9465C194.2017,-392.3271 188.9765,-382.9579 183.9591,-373.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.9615,-372.1589 179.034,-365.13 180.848,-375.5684 186.9615,-372.1589\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.2052\" y=\"-385.4793\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"326.5,-365 227.5,-365 227.5,-297 326.5,-297 326.5,-365\"/>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 3.45</text>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.208</text>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 34</text>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 30]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M237.3188,-400.9465C242.2087,-392.3271 247.5239,-382.9579 252.6278,-373.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"255.7476,-375.5549 257.6378,-365.13 249.6592,-372.1008 255.7476,-375.5549\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.2908\" y=\"-385.5285\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"92,-253.5 0,-253.5 0,-200.5 92,-200.5 92,-253.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"46\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M122.6721,-296.9465C109.8737,-285.2707 95.567,-272.219 82.8099,-260.5809\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.8409,-257.6961 75.0943,-253.5422 80.1231,-262.8675 84.8409,-257.6961\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"209.5,-261 110.5,-261 110.5,-193 209.5,-193 209.5,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[0] &lt;= 5.3</text>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.062</text>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 31</text>\n",
       "<text text-anchor=\"middle\" x=\"160\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [30, 1]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M160,-296.9465C160,-288.776 160,-279.9318 160,-271.3697\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"163.5001,-271.13 160,-261.13 156.5001,-271.13 163.5001,-271.13\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"152.5,-149.5 53.5,-149.5 53.5,-96.5 152.5,-96.5 152.5,-149.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 25</text>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [25, 0]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M141.3361,-192.9465C135.2991,-181.9316 128.5909,-169.6922 122.4953,-158.5703\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"125.4227,-156.6292 117.5471,-149.5422 119.2842,-159.9936 125.4227,-156.6292\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"263,-157 171,-157 171,-89 263,-89 263,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"217\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[1] &lt;= 3.2</text>\n",
       "<text text-anchor=\"middle\" x=\"217\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.278</text>\n",
       "<text text-anchor=\"middle\" x=\"217\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n",
       "<text text-anchor=\"middle\" x=\"217\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 1]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M178.6639,-192.9465C183.388,-184.3271 188.5231,-174.9579 193.454,-165.9611\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"196.5571,-167.5815 198.2941,-157.13 190.4186,-164.2171 196.5571,-167.5815\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"208,-53 116,-53 116,0 208,0 208,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"middle\" x=\"162\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M197.6091,-88.9777C192.651,-80.2786 187.3067,-70.9018 182.3042,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.2378,-60.2033 177.2452,-53.2485 179.1562,-63.6696 185.2378,-60.2033\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"318,-53 226,-53 226,0 318,0 318,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"272\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"272\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"middle\" x=\"272\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 0]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M236.3909,-88.9777C241.349,-80.2786 246.6933,-70.9018 251.6958,-62.1247\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"254.8438,-63.6696 256.7548,-53.2485 248.7622,-60.2033 254.8438,-63.6696\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"326.5,-253.5 227.5,-253.5 227.5,-200.5 326.5,-200.5 326.5,-253.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 30</text>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 30]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M277,-296.9465C277,-286.2621 277,-274.4254 277,-263.5742\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.5001,-263.5421 277,-253.5422 273.5001,-263.5422 280.5001,-263.5421\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"437,-253.5 345,-253.5 345,-200.5 437,-200.5 437,-253.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"391\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"391\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"391\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 0]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>8&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M314.3279,-296.9465C327.1263,-285.2707 341.433,-272.219 354.1901,-260.5809\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"356.8769,-262.8675 361.9057,-253.5422 352.1591,-257.6961 356.8769,-262.8675\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a2467c1d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": "5",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
